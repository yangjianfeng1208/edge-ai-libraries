apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ovms.fullname" . }}
  labels:
    app: {{ include "ovms.name" . }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Values.ovms.name }}
  template:
    metadata:
      labels:
        app: {{ .Values.ovms.name }}
    spec:
      {{- with .Values.nodeAffinity }}
      affinity:
        nodeAffinity:
          {{- toYaml . | nindent 10 }}
      {{- end }}
      initContainers:
        - name: init-script
          image: "python:3.10.12"
          command:
              - /bin/sh
              - -c
              - |
                if [ -f /opt/data/models/config.json ]; then
                  echo "Config file found, checking for model conversion."
                  if grep '"name": "{{ .Values.global.llmName }}"' /opt/data/models/config.json; then
                    echo "Model already converted, skipping conversion."
                  else
                    echo "Model not converted, running init script. /config/init-script.sh "{{ .Values.global.llmName }}" "{{ .Values.ovms.env.WEIGHT_FORMAT }}" "{{ .Values.global.huggingfaceToken }}""
                    . /config/init-script.sh
                  fi
                else
                  echo "No config.json found, running init script. /config/init-script.sh "{{ .Values.global.llmName }}" "{{ .Values.ovms.env.WEIGHT_FORMAT }}" "{{ .Values.global.huggingfaceToken }}""
                  . /config/init-script.sh
                fi
          args: [{{ required "Value for `global.llmName` is required!" .Values.global.llmName | quote }},"{{ .Values.ovms.env.WEIGHT_FORMAT }}","{{ .Values.global.huggingfaceToken }}","{{ .Values.global.gpu.ovmsEnabled }}"]
          env:
            - name: http_proxy
              value: {{ .Values.global.proxy.http_proxy }}
            - name: https_proxy
              value: {{ .Values.global.proxy.https_proxy }}
            - name: no_proxy
              value: "{{ .Values.global.proxy.no_proxy }},localhost,127.0.0.1,audioanalyzer,vlm-inference-microservice,videosummarybackend,videoingestion,minio-server,postgresql,video-summary-nginx,rabbitmq,multimodal-embedding-ms,vdms-dataprep,vdms-vectordb,videosearch,.svc.cluster.local"
          volumeMounts:
            - name: scripts-volume
              mountPath: /config
            - name: workspace
              mountPath: /opt/data
              subPath: ov-models
      containers:
        - name: {{ .Chart.Name }}
          image: "{{- if .Values.global.gpu.ovmsEnabled -}} {{ .Values.ovms.image.repository }}:{{ .Values.ovms.image.Gputag }} {{- else -}} {{ .Values.ovms.image.repository }}:{{ .Values.ovms.image.tag }} {{- end -}}"
          imagePullPolicy: {{ .Values.ovms.image.pullPolicy }}
          livenessProbe:
            {{- toYaml .Values.livenessProbe | nindent 12 }}
          readinessProbe:
            {{- toYaml .Values.readinessProbe | nindent 12 }}
          startupProbe:
            {{- toYaml .Values.startupProbe | nindent 12 }}
          ports:
            - containerPort: {{ .Values.ovms.containerPort }}
              name: {{ .Values.ovms.containerPortName }}
              protocol: TCP
          volumeMounts:
            - name: scripts-volume
              mountPath: /config
            - name: workspace
              mountPath: /opt/data
              subPath: ov-models
          env:
            - name: http_proxy
              value: {{ .Values.global.proxy.http_proxy }}
            - name: https_proxy
              value: {{ .Values.global.proxy.https_proxy }}
            - name: no_proxy
              value: "{{ .Values.global.proxy.no_proxy }},localhost,127.0.0.1,audioanalyzer,vlm-inference-microservice,videosummarybackend,videoingestion,minio-server,postgresql,video-summary-nginx,rabbitmq,multimodal-embedding-ms,vdms-dataprep,vdms-vectordb,videosearch,.svc.cluster.local"
            - name: WEIGHT_FORMAT
              value: {{ .Values.ovms.env.WEIGHT_FORMAT }}
          args: ["--port", "9300", "--rest_port", "8300", "--log_level", "DEBUG", "--config_path", "/opt/data/models/config.json"]
      {{- if .Values.global.gpu.ovmsEnabled }}
          resources:
            requests:
              {{ .Values.global.gpu.key }}: 1
            limits:
              {{ .Values.global.gpu.key }}: 1
          devices:
            - name: dri-device
              containerPath: /dev/dri
          securityContext:
            privileged: true
            runAsUser: 0
            runAsGroup: 0
            fsGroup: 0
      {{- end }}
      volumes:
      {{- if .Values.global.gpu.ovmsEnabled }}
        - name: dri-device
          hostPath:
            path: /dev/dri
            type: Directory
        - name: workspace
          persistentVolumeClaim:
            claimName: {{ include "ovms.fullname" . }}-gpu-pvc
      {{- else }}
        - name: workspace
          {{- if .Values.global.usePvc }}
          persistentVolumeClaim:
            claimName: {{ include "ovms.fullname" . }}-pvc
          {{- else if .Values.global.volumeHostPath }}
          hostPath:
            path: {{ .Values.global.volumeHostPath }}
            type: DirectoryOrCreate
          {{- else }}
          emptyDir: {}
          {{- end }}
      {{- end }}
        - name: scripts-volume
          configMap:
            name: {{ .Values.ovms.script.name }}
            defaultMode: 0777
