global:
  MODEL_RUNTIME: "ollama"
  EMBEDDING_MODEL:
  LLM_MODEL:
  KEEP_ALIVE: -1
  MAX_TOKENS: 1024

  # The prompt template is used to format the input to the LLM.
  # Start with folded-style (>) to avoid new lines in the multi-line template.
  # Example:
  # PROMPT_TEMPLATE: >
  #   system:
  #   Use the following pieces of context from retrieved
  #   dataset to answer the question. Do not make up an answer if there is no
  #   context provided to help answer it.
  #
  #   context:
  #   {context}
  #
  #   user:
  #   {question}
  #
  #   assistant:
  PROMPT_TEMPLATE: